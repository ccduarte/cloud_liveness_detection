{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificação facial e Reconheicimento facial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "\n",
    "def setup_directories(base_path):\n",
    "    \"\"\"Cria diretórios necessários para armazenar as imagens das faces.\"\"\"\n",
    "    os.makedirs(os.path.join(base_path, 'Face_detectada'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(base_path, 'Face_documento'), exist_ok=True)\n",
    "\n",
    "def extract_face_from_document(document_path, save_path):\n",
    "    \"\"\"Extrai a face da imagem do documento e salva.\"\"\"\n",
    "    document_image = face_recognition.load_image_file(document_path)\n",
    "    document_face_locations = face_recognition.face_locations(document_image)\n",
    "    if document_face_locations:\n",
    "        top, right, bottom, left = document_face_locations[0]\n",
    "        document_face_image = document_image[top:bottom, left:right]\n",
    "        document_face_image_bgr = cv2.cvtColor(document_face_image, cv2.COLOR_RGB2BGR)\n",
    "        cv2.imwrite(save_path, document_face_image_bgr)\n",
    "        print(\"Face extraída do documento e salva.\")\n",
    "    else:\n",
    "        print(\"Nenhum rosto encontrado no documento.\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def capture_face_from_webcam(video_capture, save_path):\n",
    "    \"\"\"Captura a face da webcam e salva quando o usuário pressiona 'a'.\"\"\"\n",
    "    print(\"Ajuste-se na câmera e pressione 'a' para capturar a face.\")\n",
    "    while True:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            continue\n",
    "        rgb_frame = frame[:, :, ::-1]  # Converte de BGR para RGB\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "\n",
    "        # Mostra o frame na janela 'Webcam'\n",
    "        cv2.imshow('Webcam', frame)\n",
    "\n",
    "        # Aguarda o usuário pressionar uma tecla\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('a'):\n",
    "            if face_locations:\n",
    "                for (top, right, bottom, left) in face_locations:\n",
    "                    cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "                    face_image = frame[top:bottom, left:right]\n",
    "                    cv2.imwrite(save_path, face_image)\n",
    "                    print(\"Face capturada da webcam e salva.\")\n",
    "                    return True\n",
    "            else:\n",
    "                print(\"Nenhum rosto detectado. Tente novamente.\")\n",
    "        elif key == ord('q'):\n",
    "            break\n",
    "    return False\n",
    "\n",
    "\n",
    "def compare_faces(image_path1, image_path2):\n",
    "    \"\"\"Compara duas faces e imprime se são da mesma pessoa ou não.\"\"\"\n",
    "    image1 = face_recognition.load_image_file(image_path1)\n",
    "    image2 = face_recognition.load_image_file(image_path2)\n",
    "    encoding1 = face_recognition.face_encodings(image1)[0]\n",
    "    encoding2 = face_recognition.face_encodings(image2)[0]\n",
    "    results = face_recognition.compare_faces([encoding1], encoding2)\n",
    "    if results[0]:\n",
    "        print(\"Os rostos são da mesma pessoa.\")\n",
    "    else:\n",
    "        print(\"Os rostos não são da mesma pessoa.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face extraída do documento e salva.\n",
      "Ajuste-se na câmera e pressione 'a' para capturar a face.\n",
      "Face capturada da webcam e salva.\n",
      "Os rostos são da mesma pessoa.\n"
     ]
    }
   ],
   "source": [
    "# Configurações iniciais\n",
    "base_path = '../src/data'\n",
    "setup_directories(base_path)\n",
    "document_path = os.path.join(base_path, 'Documento_original/document.png')\n",
    "document_face_path = os.path.join(base_path, 'Face_documento/document_face.jpg')\n",
    "captured_face_path = os.path.join(base_path, 'Face_detectada/captured_face.jpg')\n",
    "\n",
    "# Processo de extração e captura\n",
    "if extract_face_from_document(document_path, document_face_path):\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    if capture_face_from_webcam(video_capture, captured_face_path):\n",
    "        compare_faces(document_face_path, captured_face_path)\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identificação de vivacidade por piscada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import os\n",
    "\n",
    "# URL do modelo de marcos faciais\n",
    "url = \"http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2\"\n",
    "model_path = \"../src/models/shape_predictor_68_face_landmarks.dat.bz2\"  # Caminho para salvar o arquivo baixado\n",
    "\n",
    "# Baixar o arquivo se não estiver no diretório\n",
    "if not os.path.exists(model_path):\n",
    "    wget.download(url, model_path)\n",
    "\n",
    "# Descompactar o arquivo .bz2\n",
    "import bz2\n",
    "uncompressed_path = \"../src/models/shape_predictor_68_face_landmarks.dat\"  # Nome do arquivo descompactado\n",
    "if not os.path.exists(uncompressed_path):\n",
    "    with bz2.BZ2File(model_path, 'rb') as f:\n",
    "        content = f.read()\n",
    "        with open(uncompressed_path, 'wb') as new_file:\n",
    "            new_file.write(content)\n",
    "\n",
    "# Remover o arquivo .bz2 após descompactação\n",
    "os.remove(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Por favor, Pisque 3x\n",
      "Piscada 1/3 detectada\n",
      "Piscada 2/3 detectada\n",
      "Piscada 3/3 detectada\n",
      "Validação concluída!\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mO Kernel falhou ao executar o código na célula atual ou em uma célula anterior. Examine o código nas células para identificar uma possível causa da falha. Clique <a href=\"https://aka.ms/vscodeJupyterKernelCrash\">aqui</a> para obter mais informações. Consulte o <a href='command:jupyter.viewOutput'>log</a> do Jupyter para obter mais detalhes."
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import dlib\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "# Carregar o preditor de marcos faciais\n",
    "predictor_path = \"../src/models/shape_predictor_68_face_landmarks.dat\"  # Atualize com o caminho correto\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "def eye_aspect_ratio(eye):\n",
    "    A = dist.euclidean(eye[1], eye[5])\n",
    "    B = dist.euclidean(eye[2], eye[4])\n",
    "    C = dist.euclidean(eye[0], eye[3])\n",
    "    return (A + B) / (2.0 * C)\n",
    "\n",
    "def main():\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    blinks = 0\n",
    "    blink_started = False\n",
    "\n",
    "    print(\"Por favor, Pisque 3x\")\n",
    "\n",
    "    while blinks < 3:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        rgb_frame = frame[:, :, ::-1]  # Conversão de BGR para RGB\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        for face_location in face_locations:\n",
    "            top, right, bottom, left = face_location\n",
    "            cv2.rectangle(frame, (left, top), (right, bottom), (0, 255, 0), 2)\n",
    "\n",
    "            # Identificar e desenhar marcos faciais\n",
    "            face_landmarks = face_recognition.face_landmarks(rgb_frame, [face_location])\n",
    "            for face_landmark in face_landmarks:\n",
    "                left_eye = face_landmark['left_eye']\n",
    "                right_eye = face_landmark['right_eye']\n",
    "                left_ear = eye_aspect_ratio(left_eye)\n",
    "                right_ear = eye_aspect_ratio(right_eye)\n",
    "                ear = (left_ear + right_ear) / 2.0\n",
    "\n",
    "                if ear < 0.22:  # Limiar de EAR para detectar piscada\n",
    "                    if not blink_started:\n",
    "                        blink_started = True\n",
    "                elif blink_started:\n",
    "                    blinks += 1\n",
    "                    blink_started = False\n",
    "                    print(f\"Piscada {blinks}/3 detectada\")\n",
    "\n",
    "        cv2.imshow('Webcam', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    print(\"Validação concluída!\")\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import dlib\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "# Carregar o preditor de marcos faciais\n",
    "predictor_path = \"../src/models/shape_predictor_68_face_landmarks.dat\"  # Substitua pelo caminho correto do seu arquivo\n",
    "predictor = dlib.shape_predictor(predictor_path)\n",
    "\n",
    "def calculate_angle(lefteye_center, righteye_center, nose_tip):\n",
    "    # Calcular o vetor do olho esquerdo para o direito\n",
    "    eye_vector = righteye_center - lefteye_center\n",
    "    # Calcular o vetor do centro dos olhos para a ponta do nariz\n",
    "    nose_vector = nose_tip - ((lefteye_center + righteye_center) / 2)\n",
    "    \n",
    "    # Calcular o ângulo entre os dois vetores usando produto escalar\n",
    "    dot_product = np.dot(eye_vector, nose_vector)\n",
    "    magnitude = np.linalg.norm(eye_vector) * np.linalg.norm(nose_vector)\n",
    "    if magnitude == 0:\n",
    "        return 0\n",
    "    angle = np.arccos(dot_product / magnitude)\n",
    "    return np.degrees(angle)\n",
    "\n",
    "def main():\n",
    "    video_capture = cv2.VideoCapture(0)\n",
    "    turned_right = False\n",
    "\n",
    "    print(\"Por favor, vire o rosto para a direita\")\n",
    "\n",
    "    while not turned_right:\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        rgb_frame = frame[:, :, ::-1]  # Conversão de BGR para RGB\n",
    "        face_locations = face_recognition.face_locations(rgb_frame)\n",
    "        face_landmarks_list = face_recognition.face_landmarks(rgb_frame, face_locations)\n",
    "\n",
    "        for face_landmarks in face_landmarks_list:\n",
    "            lefteye_center = np.array(face_landmarks['left_eye']).mean(axis=0)\n",
    "            righteye_center = np.array(face_landmarks['right_eye']).mean(axis=0)\n",
    "            nose_tip = np.array(face_landmarks['nose_tip'][0])\n",
    "\n",
    "            # Calcular o ângulo\n",
    "            angle = calculate_angle(lefteye_center, righteye_center, nose_tip)\n",
    "\n",
    "            # Verificar se o rosto está virado suficientemente para a direita\n",
    "            if angle > 10:  # Ajuste este valor conforme necessário\n",
    "                turned_right = True\n",
    "                print(\"Rosto virado para a direita detectado!\")\n",
    "\n",
    "        cv2.imshow('Webcam', frame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    if turned_right:\n",
    "        print(\"Validação concluída!\")\n",
    "    else:\n",
    "        print(\"Não foi possível detectar a ação.\")\n",
    "\n",
    "    video_capture.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
